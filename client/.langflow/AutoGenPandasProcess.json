{"id":"00549525-3537-4203-b3ac-07dbbbc55ab6","data":{"nodes":[{"id":"TextInput-wD1Nn","type":"genericNode","position":{"x":104.77337044189142,"y":318.3840510398439},"data":{"node":{"template":{"_type":"Component","code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.base.io.text import TextComponent\nfrom langflow.io import MultilineInput, Output\nfrom langflow.schema.message import Message\n\n\nclass TextInputComponent(TextComponent):\n    display_name = \"Text Input\"\n    description = \"Get text inputs from the Playground.\"\n    icon = \"type\"\n    name = \"TextInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Text to be passed as input.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"text_response\"),\n    ]\n\n    def text_response(self) -> Message:\n        return Message(\n            text=self.input_value,\n        )\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"input_value":{"tool_mode":false,"trace_as_input":true,"multiline":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"input_value","value":"{\n                        \"columns_info\": \"market_trend_float: Market trend score ranging from -1 (negative) to 1 (positive), float.\\nsummary_content: Summarized content that reinforces the prediction, string.\",\n                        \"user_input\": \"Tính cho tôi trung bình market_trend_float và hiển thị ra bằng pandas\",\n                        \"read_parquet_path\": 'cfg[\"hdfs\"][\"data_processed\"]',\n\"write_parquet_path\": 'cfg[\"hdfs\"][\"final_data\"]',\n                        \"list_variables_available\": 'cfg: config object\\nst: streamlit object\\nhcache: cache object\\nss: session state object\\npd: pandas object\\njson: json object'\n                    }","display_name":"Text","advanced":false,"input_types":["Message"],"dynamic":false,"info":"Text to be passed as input.","title_case":false,"type":"str","_input_type":"MultilineInput"}},"description":"Get text inputs from the Playground.","icon":"type","base_classes":["Message"],"display_name":"Text Input","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"text","display_name":"Text","method":"text_response","value":"__UNDEFINED__","cache":true}],"field_order":["input_value"],"beta":false,"legacy":false,"edited":false,"metadata":{},"tool_mode":false,"lf_version":"1.1.0"},"type":"TextInput","id":"TextInput-wD1Nn"},"selected":false,"width":320,"height":233,"positionAbsolute":{"x":104.77337044189142,"y":318.3840510398439},"dragging":false},{"id":"TextOutput-TVsRz","type":"genericNode","position":{"x":2259.3445063711147,"y":294.9738102897464},"data":{"node":{"template":{"_type":"Component","code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.base.io.text import TextComponent\nfrom langflow.io import MultilineInput, Output\nfrom langflow.schema.message import Message\n\n\nclass TextOutputComponent(TextComponent):\n    display_name = \"Text Output\"\n    description = \"Display a text output in the Playground.\"\n    icon = \"type\"\n    name = \"TextOutput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Text to be passed as output.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"text_response\"),\n    ]\n\n    def text_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n        )\n        self.status = self.input_value\n        return message\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"input_value":{"tool_mode":false,"trace_as_input":true,"multiline":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"input_value","value":"","display_name":"Text","advanced":false,"input_types":["Message"],"dynamic":false,"info":"Text to be passed as output.","title_case":false,"type":"str","_input_type":"MultilineInput"}},"description":"Display a text output in the Playground.","icon":"type","base_classes":["Message"],"display_name":"Text Output","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"text","display_name":"Text","method":"text_response","value":"__UNDEFINED__","cache":true}],"field_order":["input_value"],"beta":false,"legacy":false,"edited":false,"metadata":{},"tool_mode":false,"lf_version":"1.1.0"},"type":"TextOutput","id":"TextOutput-TVsRz"},"selected":false,"width":320,"height":233,"positionAbsolute":{"x":2259.3445063711147,"y":294.9738102897464},"dragging":false},{"id":"ParseData-w38oS","type":"genericNode","position":{"x":1097.1602579041592,"y":201.18306906546218},"data":{"node":{"template":{"_type":"Component","data":{"tool_mode":false,"trace_as_metadata":true,"list":false,"trace_as_input":true,"required":false,"placeholder":"","show":true,"name":"data","value":"","display_name":"Data","advanced":false,"input_types":["Data"],"dynamic":false,"info":"The data to convert to text.","title_case":false,"type":"other","_input_type":"DataInput"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.custom import Component\nfrom langflow.helpers.data import data_to_text\nfrom langflow.io import DataInput, MultilineInput, Output, StrInput\nfrom langflow.schema.message import Message\n\n\nclass ParseDataComponent(Component):\n    display_name = \"Parse Data\"\n    description = \"Convert Data into plain text following a specified template.\"\n    icon = \"braces\"\n    name = \"ParseData\"\n\n    inputs = [\n        DataInput(name=\"data\", display_name=\"Data\", info=\"The data to convert to text.\"),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. \"\n            \"It can contain the keys {text}, {data} or any other key in the Data.\",\n            value=\"{text}\",\n        ),\n        StrInput(name=\"sep\", display_name=\"Separator\", advanced=True, value=\"\\n\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"parse_data\"),\n    ]\n\n    def parse_data(self) -> Message:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = self.template\n\n        result_string = data_to_text(template, data, sep=self.sep)\n        self.status = result_string\n        return Message(text=result_string)\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"sep":{"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"sep","value":"\n","display_name":"Separator","advanced":true,"dynamic":false,"info":"","title_case":false,"type":"str","_input_type":"StrInput"},"template":{"tool_mode":false,"trace_as_input":true,"multiline":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"template","value":"Base on columns info and User requirements write a python script follow rule:\n- Python script using for pandas spark\n- No explanation\n- Optimal code run fast on multi worker\n- Non-technical users should not add comment option\n- Optimize comments\n- Must todo is must have\n\n## Columns info\n{columns_info}\n\n## User requirements\n{user_input}\n\n## Addition Infomation\n- Read parquet path: {read_parquet_path}\n- Write parquet path: {write_parquet_path}\n\n## Variables available\n{list_variables_available}\n\n## Sample good format code\n\npython\n```\ndef name_tmp_function(cfg):\n\timport pandas as pd\n\tfrom pyspark.sql import SparkSession\n\tfrom pyspark.sql import functions as F\n\t\n\t# Initialize SparkSession\n\tspark = SparkSession.builder.appName(\"Name-app\").getOrCreate()\n\t\n\t# Read data from parquet file\n    data_processed_path = `Read parquet path`\n    df = spark.read.parquet(data_processed_path)\n\t\n\t# Must todo: Process data by spark here\n\t\n\tdata_final_process_path = `Write parquet path`\n\t# Must todo: Write data processed to `Write parquet path`\n\t\n\t# Convert the result to a pandas DataFrame\n    pandas_df = pd.DataFrame(....)\n\t\n\t# Must todo: Display the pandas DataFrame to streamlit\n\tst.write(pandas_df)\n\t# Show download button to streamlit\n\t# Some good UI, UX if needed here\n\n    # Stop the SparkSession\n\tif not spark._jsc.sc().isStopped():\n\t\tspark.stop()\n\n# Final run main function\nname_tmp_function(cfg)\n```","display_name":"Template","advanced":false,"input_types":["Message"],"dynamic":false,"info":"The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.","title_case":false,"type":"str","_input_type":"MultilineInput"}},"description":"Convert Data into plain text following a specified template.","icon":"braces","base_classes":["Message"],"display_name":"Parse Data","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"text","display_name":"Text","method":"parse_data","value":"__UNDEFINED__","cache":true}],"field_order":["data","template","sep"],"beta":false,"legacy":false,"edited":false,"metadata":{},"tool_mode":false,"category":"processing","key":"ParseData","lf_version":"1.1.0"},"type":"ParseData","id":"ParseData-w38oS"},"selected":true,"width":320,"height":301,"positionAbsolute":{"x":1097.1602579041592,"y":201.18306906546218},"dragging":false},{"id":"ParseJSONData-MPtUx","type":"genericNode","position":{"x":592.2409311924073,"y":246.45169835686067},"data":{"node":{"template":{"_type":"Component","input_value":{"trace_as_metadata":true,"list":false,"required":true,"placeholder":"","show":true,"name":"input_value","value":"","display_name":"Input","advanced":false,"input_types":["Message","Data"],"dynamic":false,"info":"Data object to filter.","title_case":false,"type":"other","_input_type":"HandleInput"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"import json\nfrom json import JSONDecodeError\n\nimport jq\nfrom json_repair import repair_json\nfrom loguru import logger\n\nfrom langflow.custom import Component\nfrom langflow.inputs import HandleInput, MessageTextInput\nfrom langflow.io import Output\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\n\n\nclass ParseJSONDataComponent(Component):\n    display_name = \"Parse JSON\"\n    description = \"Convert and extract JSON fields.\"\n    icon = \"braces\"\n    name = \"ParseJSONData\"\n    legacy: bool = True\n\n    inputs = [\n        HandleInput(\n            name=\"input_value\",\n            display_name=\"Input\",\n            info=\"Data object to filter.\",\n            required=True,\n            input_types=[\"Message\", \"Data\"],\n        ),\n        MessageTextInput(\n            name=\"query\",\n            display_name=\"JQ Query\",\n            info=\"JQ Query to filter the data. The input is always a JSON list.\",\n            required=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Filtered Data\", name=\"filtered_data\", method=\"filter_data\"),\n    ]\n\n    def _parse_data(self, input_value) -> str:\n        if isinstance(input_value, Message) and isinstance(input_value.text, str):\n            return input_value.text\n        if isinstance(input_value, Data):\n            return json.dumps(input_value.data)\n        return str(input_value)\n\n    def filter_data(self) -> list[Data]:\n        to_filter = self.input_value\n        if not to_filter:\n            return []\n        # Check if input is a list\n        if isinstance(to_filter, list):\n            to_filter = [self._parse_data(f) for f in to_filter]\n        else:\n            to_filter = self._parse_data(to_filter)\n\n        # If input is not a list, don't wrap it in a list\n        if not isinstance(to_filter, list):\n            to_filter = repair_json(to_filter)\n            try:\n                to_filter_as_dict = json.loads(to_filter)\n            except JSONDecodeError:\n                try:\n                    to_filter_as_dict = json.loads(repair_json(to_filter))\n                except JSONDecodeError as e:\n                    msg = f\"Invalid JSON: {e}\"\n                    raise ValueError(msg) from e\n        else:\n            to_filter = [repair_json(f) for f in to_filter]\n            to_filter_as_dict = []\n            for f in to_filter:\n                try:\n                    to_filter_as_dict.append(json.loads(f))\n                except JSONDecodeError:\n                    try:\n                        to_filter_as_dict.append(json.loads(repair_json(f)))\n                    except JSONDecodeError as e:\n                        msg = f\"Invalid JSON: {e}\"\n                        raise ValueError(msg) from e\n            to_filter = to_filter_as_dict\n\n        full_filter_str = json.dumps(to_filter_as_dict)\n\n        logger.info(\"to_filter: \", to_filter)\n\n        results = jq.compile(self.query).input_text(full_filter_str).all()\n        logger.info(\"results: \", results)\n        return [Data(data=value) if isinstance(value, dict) else Data(text=str(value)) for value in results]\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"query":{"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":true,"placeholder":"","show":true,"name":"query","value":".","display_name":"JQ Query","advanced":false,"input_types":["Message"],"dynamic":false,"info":"JQ Query to filter the data. The input is always a JSON list.","title_case":false,"type":"str","_input_type":"MessageTextInput"}},"description":"Convert and extract JSON fields.","icon":"braces","base_classes":["Data"],"display_name":"Parse JSON","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Data"],"selected":"Data","name":"filtered_data","display_name":"Filtered Data","method":"filter_data","value":"__UNDEFINED__","cache":true}],"field_order":["input_value","query"],"beta":false,"legacy":true,"edited":false,"metadata":{},"tool_mode":false,"category":"processing","key":"ParseJSONData","lf_version":"1.1.0"},"type":"ParseJSONData","id":"ParseJSONData-MPtUx"},"selected":false,"width":320,"height":281,"positionAbsolute":{"x":592.2409311924073,"y":246.45169835686067},"dragging":false},{"id":"GoogleGenerativeAIModel-18OHw","type":"genericNode","position":{"x":1647.3482139073103,"y":-82.58191422588148},"data":{"node":{"template":{"_type":"Component","output_parser":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"output_parser","value":"","display_name":"Output Parser","advanced":true,"input_types":["OutputParser"],"dynamic":false,"info":"The parser to use to parse the output of the model","title_case":false,"type":"other","_input_type":"HandleInput"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from pydantic.v1 import SecretStr\n\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.field_typing import LanguageModel\nfrom langflow.inputs import DropdownInput, FloatInput, IntInput, SecretStrInput\nfrom langflow.inputs.inputs import HandleInput\n\n\nclass GoogleGenerativeAIComponent(LCModelComponent):\n    display_name = \"Google Generative AI\"\n    description = \"Generate text using Google Generative AI.\"\n    icon = \"GoogleGenerativeAI\"\n    name = \"GoogleGenerativeAIModel\"\n\n    inputs = [\n        *LCModelComponent._base_inputs,\n        IntInput(\n            name=\"max_output_tokens\", display_name=\"Max Output Tokens\", info=\"The maximum number of tokens to generate.\"\n        ),\n        DropdownInput(\n            name=\"model\",\n            display_name=\"Model\",\n            info=\"The name of the model to use.\",\n            options=[\"gemini-2.5-flash-preview-05-20\", \"gemini-2.0-flash-exp\", \"gemini-1.5-pro\", \"gemini-1.5-flash\", \"gemini-1.0-pro\", \"gemini-1.0-pro-vision\"],\n            value=\"gemini-2.5-flash-preview-05-20\",\n        ),\n        SecretStrInput(\n            name=\"google_api_key\",\n            display_name=\"Google API Key\",\n            info=\"The Google API Key to use for the Google Generative AI.\",\n        ),\n        FloatInput(\n            name=\"top_p\",\n            display_name=\"Top P\",\n            info=\"The maximum cumulative probability of tokens to consider when sampling.\",\n            advanced=True,\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        IntInput(\n            name=\"n\",\n            display_name=\"N\",\n            info=\"Number of chat completions to generate for each prompt. \"\n            \"Note that the API may not return the full n completions if duplicates are generated.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"top_k\",\n            display_name=\"Top K\",\n            info=\"Decode using top-k sampling: consider the set of top_k most probable tokens. Must be positive.\",\n            advanced=True,\n        ),\n        HandleInput(\n            name=\"output_parser\",\n            display_name=\"Output Parser\",\n            info=\"The parser to use to parse the output of the model\",\n            advanced=True,\n            input_types=[\"OutputParser\"],\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        try:\n            from langchain_google_genai import ChatGoogleGenerativeAI\n        except ImportError as e:\n            msg = \"The 'langchain_google_genai' package is required to use the Google Generative AI model.\"\n            raise ImportError(msg) from e\n\n        google_api_key = self.google_api_key\n        model = self.model\n        max_output_tokens = self.max_output_tokens\n        temperature = self.temperature\n        top_k = self.top_k\n        top_p = self.top_p\n        n = self.n\n\n        return ChatGoogleGenerativeAI(\n            model=model,\n            max_output_tokens=max_output_tokens or None,\n            temperature=temperature,\n            top_k=top_k or None,\n            top_p=top_p or None,\n            n=n or 1,\n            google_api_key=SecretStr(google_api_key).get_secret_value(),\n        )\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"google_api_key":{"load_from_db":false,"required":false,"placeholder":"","show":true,"name":"google_api_key","value":"","display_name":"Google API Key","advanced":false,"input_types":["Message"],"dynamic":false,"info":"The Google API Key to use for the Google Generative AI.","title_case":false,"password":true,"type":"str","_input_type":"SecretStrInput"},"input_value":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"input_value","value":"","display_name":"Input","advanced":false,"input_types":["Message"],"dynamic":false,"info":"","title_case":false,"type":"str","_input_type":"MessageInput"},"max_output_tokens":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"max_output_tokens","value":"","display_name":"Max Output Tokens","advanced":false,"dynamic":false,"info":"The maximum number of tokens to generate.","title_case":false,"type":"int","_input_type":"IntInput"},"model":{"tool_mode":false,"trace_as_metadata":true,"options":["gemini-2.5-flash-preview-05-20","gemini-2.0-flash-exp","gemini-1.5-pro","gemini-1.5-flash","gemini-1.0-pro","gemini-1.0-pro-vision"],"combobox":false,"required":false,"placeholder":"","show":true,"name":"model","value":"gemini-2.5-flash-preview-05-20","display_name":"Model","advanced":false,"dynamic":false,"info":"The name of the model to use.","title_case":false,"type":"str","_input_type":"DropdownInput"},"n":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"n","value":"","display_name":"N","advanced":true,"dynamic":false,"info":"Number of chat completions to generate for each prompt. Note that the API may not return the full n completions if duplicates are generated.","title_case":false,"type":"int","_input_type":"IntInput"},"stream":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"stream","value":false,"display_name":"Stream","advanced":false,"dynamic":false,"info":"Stream the response from the model. Streaming works only in Chat.","title_case":false,"type":"bool","_input_type":"BoolInput"},"system_message":{"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"system_message","value":"","display_name":"System Message","advanced":false,"input_types":["Message"],"dynamic":false,"info":"System message to pass to the model.","title_case":false,"type":"str","_input_type":"MessageTextInput"},"temperature":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"temperature","value":0.8,"display_name":"Temperature","advanced":false,"dynamic":false,"info":"","title_case":false,"type":"float","_input_type":"FloatInput","load_from_db":false},"top_k":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"top_k","value":"","display_name":"Top K","advanced":true,"dynamic":false,"info":"Decode using top-k sampling: consider the set of top_k most probable tokens. Must be positive.","title_case":false,"type":"int","_input_type":"IntInput"},"top_p":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"top_p","value":"","display_name":"Top P","advanced":true,"dynamic":false,"info":"The maximum cumulative probability of tokens to consider when sampling.","title_case":false,"type":"float","_input_type":"FloatInput"}},"description":"Generate text using Google Generative AI.","icon":"GoogleGenerativeAI","base_classes":["LanguageModel","Message"],"display_name":"Google Generative AI","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"text_output","display_name":"Text","method":"text_response","value":"__UNDEFINED__","cache":true,"required_inputs":[]},{"types":["LanguageModel"],"selected":"LanguageModel","name":"model_output","display_name":"Language Model","method":"build_model","value":"__UNDEFINED__","cache":true,"required_inputs":[]}],"field_order":["input_value","system_message","stream","max_output_tokens","model","google_api_key","top_p","temperature","n","top_k","output_parser"],"beta":false,"legacy":false,"edited":true,"metadata":{},"tool_mode":false,"lf_version":"1.1.0"},"type":"GoogleGenerativeAIModel","id":"GoogleGenerativeAIModel-18OHw"},"selected":false,"width":320,"height":755,"positionAbsolute":{"x":1647.3482139073103,"y":-82.58191422588148},"dragging":false}],"edges":[{"source":"TextInput-wD1Nn","sourceHandle":"{œdataTypeœ:œTextInputœ,œidœ:œTextInput-wD1Nnœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}","target":"ParseJSONData-MPtUx","targetHandle":"{œfieldNameœ:œinput_valueœ,œidœ:œParseJSONData-MPtUxœ,œinputTypesœ:[œMessageœ,œDataœ],œtypeœ:œotherœ}","data":{"targetHandle":{"fieldName":"input_value","id":"ParseJSONData-MPtUx","inputTypes":["Message","Data"],"type":"other"},"sourceHandle":{"dataType":"TextInput","id":"TextInput-wD1Nn","name":"text","output_types":["Message"]}},"id":"reactflow__edge-TextInput-wD1Nn{œdataTypeœ:œTextInputœ,œidœ:œTextInput-wD1Nnœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-ParseJSONData-MPtUx{œfieldNameœ:œinput_valueœ,œidœ:œParseJSONData-MPtUxœ,œinputTypesœ:[œMessageœ,œDataœ],œtypeœ:œotherœ}","className":"","animated":false},{"source":"ParseJSONData-MPtUx","sourceHandle":"{œdataTypeœ:œParseJSONDataœ,œidœ:œParseJSONData-MPtUxœ,œnameœ:œfiltered_dataœ,œoutput_typesœ:[œDataœ]}","target":"ParseData-w38oS","targetHandle":"{œfieldNameœ:œdataœ,œidœ:œParseData-w38oSœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}","data":{"targetHandle":{"fieldName":"data","id":"ParseData-w38oS","inputTypes":["Data"],"type":"other"},"sourceHandle":{"dataType":"ParseJSONData","id":"ParseJSONData-MPtUx","name":"filtered_data","output_types":["Data"]}},"id":"reactflow__edge-ParseJSONData-MPtUx{œdataTypeœ:œParseJSONDataœ,œidœ:œParseJSONData-MPtUxœ,œnameœ:œfiltered_dataœ,œoutput_typesœ:[œDataœ]}-ParseData-w38oS{œfieldNameœ:œdataœ,œidœ:œParseData-w38oSœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}","className":"","animated":false},{"source":"ParseData-w38oS","sourceHandle":"{œdataTypeœ:œParseDataœ,œidœ:œParseData-w38oSœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}","target":"GoogleGenerativeAIModel-18OHw","targetHandle":"{œfieldNameœ:œinput_valueœ,œidœ:œGoogleGenerativeAIModel-18OHwœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"input_value","id":"GoogleGenerativeAIModel-18OHw","inputTypes":["Message"],"type":"str"},"sourceHandle":{"dataType":"ParseData","id":"ParseData-w38oS","name":"text","output_types":["Message"]}},"id":"reactflow__edge-ParseData-w38oS{œdataTypeœ:œParseDataœ,œidœ:œParseData-w38oSœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-GoogleGenerativeAIModel-18OHw{œfieldNameœ:œinput_valueœ,œidœ:œGoogleGenerativeAIModel-18OHwœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","className":"","animated":false},{"source":"GoogleGenerativeAIModel-18OHw","sourceHandle":"{œdataTypeœ:œGoogleGenerativeAIModelœ,œidœ:œGoogleGenerativeAIModel-18OHwœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}","target":"TextOutput-TVsRz","targetHandle":"{œfieldNameœ:œinput_valueœ,œidœ:œTextOutput-TVsRzœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"input_value","id":"TextOutput-TVsRz","inputTypes":["Message"],"type":"str"},"sourceHandle":{"dataType":"GoogleGenerativeAIModel","id":"GoogleGenerativeAIModel-18OHw","name":"text_output","output_types":["Message"]}},"id":"reactflow__edge-GoogleGenerativeAIModel-18OHw{œdataTypeœ:œGoogleGenerativeAIModelœ,œidœ:œGoogleGenerativeAIModel-18OHwœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-TextOutput-TVsRz{œfieldNameœ:œinput_valueœ,œidœ:œTextOutput-TVsRzœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","className":"","animated":false}],"viewport":{"x":-1238.7770491760589,"y":97.3931069534317,"zoom":0.8881494613468803}},"description":"Unravel the Art of Articulation.","name":"AutoGenPandasProcess","last_tested_version":"1.1.0","endpoint_name":null,"is_component":false}