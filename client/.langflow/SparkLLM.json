{"id":"62afc92d-49b1-4ab7-807f-fe7da8223f0f","data":{"nodes":[{"id":"TextInput-O9glu","type":"genericNode","position":{"x":-338.26852453127543,"y":207.385313234112},"data":{"node":{"template":{"_type":"Component","code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.base.io.text import TextComponent\nfrom langflow.io import MultilineInput, Output\nfrom langflow.schema.message import Message\n\n\nclass TextInputComponent(TextComponent):\n    display_name = \"Text Input\"\n    description = \"Get text inputs from the Playground.\"\n    icon = \"type\"\n    name = \"TextInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Text to be passed as input.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"text_response\"),\n    ]\n\n    def text_response(self) -> Message:\n        return Message(\n            text=self.input_value,\n        )\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"input_value":{"tool_mode":false,"trace_as_input":true,"multiline":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"input_value","value":"{\n  \"columns_information\": \"datetime: Date and time of the content, format: YYYY-MM-DD HH:MM:SS\\ncontent: Full text content scraped from the website, type: string\\nsummary: Summarized content focusing on crypto influence, type: string\\ncrypto_influence_score: Numerical score (0-10) representing the content's influence on crypto, type: float\\ninfluence_description: Explanation of how the content influences crypto, type: string\",\n  \"given_data\": \"Press Releases\\nContact us\\nADVERTISE\\nBITCOIN\\nALTCOINS\\nTECH\\nINDUSTRY\\nHOW TO\\nEVENTS\\nPLAY GAMES\\nCASINOS\\nSTAKE: 200% BONUS\\nBreaking News: Craig Wright Sentenced To 1 Year In Prison: The Self-Proclaimed Bitcoin Creator Faces Justice\\nBitcoin Price Prediction: BTC Breaks $100K, Is This The Year Of Crypto? New Viral Altcoin Sensation Raises $1M In Record Time\\n by Bitcoinist\\n 2 weeks ago\\nin Press releases\\n\\nDecember has been a good month for most cryptocurrencies, especially Bitcoin. Just a few days to days into December BTC price broke the most anticipated point, breaking the $100,000 mark, for the first time ever. Aside from Bitcoin asserting dominance this month, a new altcoin Yeti Ouro (YETIO) has been going viral after raising over $1 million in its presale.\\n\\nBitcoin Price News – The Journey To $100K\\n\\nFor a very long time, investors and enthusiasts have been looking forward to Bitcoin hitting the $100k mark. It all seemed like it would be achieved right after the last bitcoin halving this year but that was not the case until recently.\\n\\nOn December 3rd BTC price hit $100,000 for the first time and with the momentum still alive Bitcoins ascended past $100K to hit an all-time high of $103,900 2 days later. Despite the momentum, Bitcoin has since then faced a few setbacks dipping to $97,820.66 today. With a market cap of $1.93 trillion, the coin’s dominance remains unmatched.\\n\\nWhat Propelled BTC to $100K?\\n\\nSince the start of the year after the SEC approved bitcoin ETFs including BlackRock Bitcoin ETF, Bitcoin has seen an increased institutional adoption.  Major institutional players continue to view Bitcoin as a hedge against inflation and an alternative store of value.\\n\\nThe recent win by a pro-crypto Government has also boosted the confidence of investors\\n\\n\\nYeti Ouro: The New Viral Altcoin Raises $1M In Record Time\\n\\nEmerging as a utility-driven meme coin, Yeti Ouro has raised an impressive $1,004,241 so far in its presale phase, getting the attention of the crypto community. The project is looking to complete stage 1 of presale having completed about 84% already.\\n\\nWhat Makes Yeti Ouro Special?\\n\\nWith a capped supply of 1 billion tokens, the project is designed to appreciate. 50% of these tokens have been allocated to early investors with the current price of Yeti Ouro standing at $0.012. \\n\\nYeti Ouro is not just a token, it has integrated a Play-to-Earn (P2E) racing game built on Unreal Engine, Yeti Go. This integration offers players the chance to earn and use Yeti Ouro tokens in-game for purchases, race entry fees, and staking.\\n\\nHaving raised over $1 million in presale which launched recently, Yeti Ouro’s success reflects strong community backing and a growing belief in its potential as a 100X meme coin. Early investors have a rare chance to enjoy such RIO. \\n\\nWhile Bitcoin aims for $150K next, Yeti Ouro is looking to launch stage 2 of presale. Yeti Ouro’s strong presale performance demonstrates the appetite for fresh, and with the community growing by the day, gaining by 100x or more is a realistic target for utility-driven projects\\n\\nJoin The Yeti Ouro Community \\n\\nWebsite: https://yetiouro.io/\\n\\nX (Formally Twitter): https://x.com/yetiouro\\n\\nTelegram: https://t.me/yetiouroofficial\\n\\nDiscord: https://discord.gg/YtUsEZ2Zr\\n\\nDisclaimer: This is a paid release. The statements, views and opinions expressed in this column are solely those of the content provider and do not necessarily represent those of Bitcoinist. Bitcoinist does not guarantee the accuracy or timeliness of information available in such content. Do your research and invest at your own risk.\\n\\nSign Up for Our Newsletter!\\n\\nFor updates and exclusive offers enter your email.\\n\\n Sign Up\\n I consent to my submitted data being collected and stored.\\nBitcoinist\\n\\nBitcoinist is the ultimate news and review site for the crypto currency community!\\n\\nRelated Posts\\nBreaking Down Qubetics’ Wallet Secrets, Binance’s Licensing Strategies, and Litecoin’s Network Growth in Today’s Crypto News\\n19 hours ago\\nSolana Price Prediction: 2025 Could be The Year SOL Joins the $1000 Club, But This Must Happen First\\n2 days ago\\nWill Monsta Mash ($MASH) Outpace Tron (TRX) & Solana (SOL) in the next Bull Run?\\n3 days ago\\nDon’t Get Left Behind: New Meme Coins to Invest in for Short Term That Are Making Waves!\\n3 days ago\\nRipple (XRP): Is Another Leg Up Imminent, or Will Investors Be Left Holding Their Bags for Another 7 Years?\\n3 days ago\\nBNB (BNB) Inches Closer To $800, Sui (SUI) Makes New ATH Again—Lunex Network (LNEX) Raises Over $5 Million\\n3 days ago\\nPress Releases\\nBreaking Down Qubetics’ Wallet Secrets, Binance’s...\\n19 hours ago\\nSolana Price Prediction: 2025 Could be The Year SOL Joins...\\n2 days ago\\nWill Monsta Mash ($MASH) Outpace Tron (TRX) & Solana...\\n3 days ago\\nDon’t Get Left Behind: New Meme Coins to Invest in for...\\n3 days ago\\nRipple (XRP): Is Another Leg Up Imminent, or Will Investors...\\n3 days ago\\n\\nBitcoin news portal providing breaking news, guides, price analysis about decentralized digital money & blockchain technology.\\n\\nBITCOIN\\nNews\\nPrice\\nBusinesses\\nAcceptance\\nTechnology\\nInvestment\\nRegulation\\nReviews\\nALTCOINS\\nNews\\nPrice\\nEthereum\\nRipple\\nLitecoin\\nEOS\\nCATEGORIES\\nBlockchain\\nSecurity\\nFinTech\\nTechnology\\nTrending\\nBreaking News\\nPress Releases\\nHow to\\nABOUT US\\nAdvertise\\nContact us\\nEditorial Policy\\nPrivacy Policy\\n© 2024 Bitcoinist.com. All Rights Reserved.\\nBitcoin\\nAltcoins\\nTech\\nIndustry\\nHow to\\nEvents\\nPlay Games\\nCasinos\\nStake: 200% Bonus\\nADVERTISE\\n\\n© 2023 Bitcoinist. All Rights Reserved.\\n\\nThis website uses cookies. By continuing to use this website you are giving consent to cookies being used. Visit our Privacy Center or Cookie Policy. I Agree\"\n}","display_name":"Text","advanced":false,"input_types":["Message"],"dynamic":false,"info":"Text to be passed as input.","title_case":false,"type":"str","_input_type":"MultilineInput"}},"description":"Get text inputs from the Playground.","icon":"type","base_classes":["Message"],"display_name":"Text Input","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"text","display_name":"Text","method":"text_response","value":"__UNDEFINED__","cache":true}],"field_order":["input_value"],"beta":false,"legacy":false,"edited":false,"metadata":{},"tool_mode":false,"lf_version":"1.1.0"},"type":"TextInput","id":"TextInput-O9glu"},"selected":false,"width":320,"height":231,"positionAbsolute":{"x":-338.26852453127543,"y":207.385313234112},"dragging":false},{"id":"ParseData-htcyL","type":"genericNode","position":{"x":917.7620190856803,"y":537.4201743721101},"data":{"node":{"template":{"_type":"Component","data":{"tool_mode":false,"trace_as_metadata":true,"list":false,"trace_as_input":true,"required":false,"placeholder":"","show":true,"name":"data","value":"","display_name":"Data","advanced":false,"input_types":["Data"],"dynamic":false,"info":"The data to convert to text.","title_case":false,"type":"other","_input_type":"DataInput"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.custom import Component\nfrom langflow.helpers.data import data_to_text\nfrom langflow.io import DataInput, MultilineInput, Output, StrInput\nfrom langflow.schema.message import Message\n\n\nclass ParseDataComponent(Component):\n    display_name = \"Parse Data\"\n    description = \"Convert Data into plain text following a specified template.\"\n    icon = \"braces\"\n    name = \"ParseData\"\n\n    inputs = [\n        DataInput(name=\"data\", display_name=\"Data\", info=\"The data to convert to text.\"),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. \"\n            \"It can contain the keys {text}, {data} or any other key in the Data.\",\n            value=\"{text}\",\n        ),\n        StrInput(name=\"sep\", display_name=\"Separator\", advanced=True, value=\"\\n\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"parse_data\"),\n    ]\n\n    def parse_data(self) -> Message:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = self.template\n\n        result_string = data_to_text(template, data, sep=self.sep)\n        self.status = result_string\n        return Message(text=result_string)\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"sep":{"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"sep","value":"\n","display_name":"Separator","advanced":true,"dynamic":false,"info":"","title_case":false,"type":"str","_input_type":"StrInput"},"template":{"tool_mode":false,"trace_as_input":true,"multiline":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"template","value":"Base on columns information, process given data and return response must follow rules:\n- No explanation\n- Response must in JSON format\n- Response must and only have key name in columns information\n- Response is a columns data for a table data (pandas)\n- Response format example:\n{{\n\"column name 1\": data processed,\n...\n}}\n\n## Columns information\n```\n{columns_information}\n```\n\n## Given data\n```\n{given_data}\n```","display_name":"Template","advanced":false,"input_types":["Message"],"dynamic":false,"info":"The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.","title_case":false,"type":"str","_input_type":"MultilineInput"}},"description":"Convert Data into plain text following a specified template.","icon":"braces","base_classes":["Message"],"display_name":"Parse Data","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"text","display_name":"Text","method":"parse_data","value":"__UNDEFINED__","cache":true}],"field_order":["data","template","sep"],"beta":false,"legacy":false,"edited":false,"metadata":{},"tool_mode":false,"category":"processing","key":"ParseData","lf_version":"1.1.0"},"type":"ParseData","id":"ParseData-htcyL"},"selected":false,"width":320,"height":299,"positionAbsolute":{"x":917.7620190856803,"y":537.4201743721101},"dragging":false},{"id":"ParseJSONData-fLPKf","type":"genericNode","position":{"x":349.2598573544815,"y":110.8853941035513},"data":{"node":{"template":{"_type":"Component","input_value":{"trace_as_metadata":true,"list":false,"required":true,"placeholder":"","show":true,"name":"input_value","value":"","display_name":"Input","advanced":false,"input_types":["Message","Data"],"dynamic":false,"info":"Data object to filter.","title_case":false,"type":"other","_input_type":"HandleInput"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"import json\nfrom json import JSONDecodeError\n\nimport jq\nfrom json_repair import repair_json\nfrom loguru import logger\n\nfrom langflow.custom import Component\nfrom langflow.inputs import HandleInput, MessageTextInput\nfrom langflow.io import Output\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\n\n\nclass ParseJSONDataComponent(Component):\n    display_name = \"Parse JSON\"\n    description = \"Convert and extract JSON fields.\"\n    icon = \"braces\"\n    name = \"ParseJSONData\"\n    legacy: bool = True\n\n    inputs = [\n        HandleInput(\n            name=\"input_value\",\n            display_name=\"Input\",\n            info=\"Data object to filter.\",\n            required=True,\n            input_types=[\"Message\", \"Data\"],\n        ),\n        MessageTextInput(\n            name=\"query\",\n            display_name=\"JQ Query\",\n            info=\"JQ Query to filter the data. The input is always a JSON list.\",\n            required=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Filtered Data\", name=\"filtered_data\", method=\"filter_data\"),\n    ]\n\n    def _parse_data(self, input_value) -> str:\n        if isinstance(input_value, Message) and isinstance(input_value.text, str):\n            return input_value.text\n        if isinstance(input_value, Data):\n            return json.dumps(input_value.data)\n        return str(input_value)\n\n    def filter_data(self) -> list[Data]:\n        to_filter = self.input_value\n        if not to_filter:\n            return []\n        # Check if input is a list\n        if isinstance(to_filter, list):\n            to_filter = [self._parse_data(f) for f in to_filter]\n        else:\n            to_filter = self._parse_data(to_filter)\n\n        # If input is not a list, don't wrap it in a list\n        if not isinstance(to_filter, list):\n            to_filter = repair_json(to_filter)\n            try:\n                to_filter_as_dict = json.loads(to_filter)\n            except JSONDecodeError:\n                try:\n                    to_filter_as_dict = json.loads(repair_json(to_filter))\n                except JSONDecodeError as e:\n                    msg = f\"Invalid JSON: {e}\"\n                    raise ValueError(msg) from e\n        else:\n            to_filter = [repair_json(f) for f in to_filter]\n            to_filter_as_dict = []\n            for f in to_filter:\n                try:\n                    to_filter_as_dict.append(json.loads(f))\n                except JSONDecodeError:\n                    try:\n                        to_filter_as_dict.append(json.loads(repair_json(f)))\n                    except JSONDecodeError as e:\n                        msg = f\"Invalid JSON: {e}\"\n                        raise ValueError(msg) from e\n            to_filter = to_filter_as_dict\n\n        full_filter_str = json.dumps(to_filter_as_dict)\n\n        logger.info(\"to_filter: \", to_filter)\n\n        results = jq.compile(self.query).input_text(full_filter_str).all()\n        logger.info(\"results: \", results)\n        return [Data(data=value) if isinstance(value, dict) else Data(text=str(value)) for value in results]\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"query":{"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":true,"placeholder":"","show":true,"name":"query","value":".","display_name":"JQ Query","advanced":false,"input_types":["Message"],"dynamic":false,"info":"JQ Query to filter the data. The input is always a JSON list.","title_case":false,"type":"str","_input_type":"MessageTextInput"}},"description":"Convert and extract JSON fields.","icon":"braces","base_classes":["Data"],"display_name":"Parse JSON","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Data"],"selected":"Data","name":"filtered_data","display_name":"Filtered Data","method":"filter_data","value":"__UNDEFINED__","cache":true}],"field_order":["input_value","query"],"beta":false,"legacy":true,"edited":false,"metadata":{},"tool_mode":false,"category":"processing","key":"ParseJSONData","lf_version":"1.1.0"},"type":"ParseJSONData","id":"ParseJSONData-fLPKf"},"selected":false,"width":320,"height":280,"positionAbsolute":{"x":349.2598573544815,"y":110.8853941035513},"dragging":false},{"id":"GoogleGenerativeAIModel-WF3Qa","type":"genericNode","position":{"x":1368.9854733326504,"y":75.78075365427628},"data":{"node":{"template":{"_type":"Component","output_parser":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"output_parser","value":"","display_name":"Output Parser","advanced":true,"input_types":["OutputParser"],"dynamic":false,"info":"The parser to use to parse the output of the model","title_case":false,"type":"other","_input_type":"HandleInput"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from pydantic.v1 import SecretStr\n\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.field_typing import LanguageModel\nfrom langflow.inputs import DropdownInput, FloatInput, IntInput, SecretStrInput\nfrom langflow.inputs.inputs import HandleInput\n\n\nclass GoogleGenerativeAIComponent(LCModelComponent):\n    display_name = \"Google Generative AI\"\n    description = \"Generate text using Google Generative AI.\"\n    icon = \"GoogleGenerativeAI\"\n    name = \"GoogleGenerativeAIModel\"\n\n    inputs = [\n        *LCModelComponent._base_inputs,\n        IntInput(\n            name=\"max_output_tokens\", display_name=\"Max Output Tokens\", info=\"The maximum number of tokens to generate.\"\n        ),\n        StrInput(\n            name=\"model\",\n            display_name=\"Model\",\n            info=\"The name of the model to use.\",\n            value=\"gemini-1.5-pro\",\n        ),\n        SecretStrInput(\n            name=\"google_api_key\",\n            display_name=\"Google API Key\",\n            info=\"The Google API Key to use for the Google Generative AI.\",\n        ),\n        FloatInput(\n            name=\"top_p\",\n            display_name=\"Top P\",\n            info=\"The maximum cumulative probability of tokens to consider when sampling.\",\n            advanced=True,\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        IntInput(\n            name=\"n\",\n            display_name=\"N\",\n            info=\"Number of chat completions to generate for each prompt. \"\n            \"Note that the API may not return the full n completions if duplicates are generated.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"top_k\",\n            display_name=\"Top K\",\n            info=\"Decode using top-k sampling: consider the set of top_k most probable tokens. Must be positive.\",\n            advanced=True,\n        ),\n        HandleInput(\n            name=\"output_parser\",\n            display_name=\"Output Parser\",\n            info=\"The parser to use to parse the output of the model\",\n            advanced=True,\n            input_types=[\"OutputParser\"],\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        try:\n            from langchain_google_genai import ChatGoogleGenerativeAI\n        except ImportError as e:\n            msg = \"The 'langchain_google_genai' package is required to use the Google Generative AI model.\"\n            raise ImportError(msg) from e\n\n        google_api_key = self.google_api_key\n        model = self.model\n        max_output_tokens = self.max_output_tokens\n        temperature = self.temperature\n        top_k = self.top_k\n        top_p = self.top_p\n        n = self.n\n\n        return ChatGoogleGenerativeAI(\n            model=model,\n            max_output_tokens=max_output_tokens or None,\n            temperature=temperature,\n            top_k=top_k or None,\n            top_p=top_p or None,\n            n=n or 1,\n            google_api_key=SecretStr(google_api_key).get_secret_value(),\n        )\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"google_api_key":{"load_from_db":false,"required":false,"placeholder":"","show":true,"name":"google_api_key","value":"","display_name":"Google API Key","advanced":false,"input_types":["Message"],"dynamic":false,"info":"The Google API Key to use for the Google Generative AI.","title_case":false,"password":true,"type":"str","_input_type":"SecretStrInput"},"input_value":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"input_value","value":"","display_name":"Input","advanced":false,"input_types":["Message"],"dynamic":false,"info":"","title_case":false,"type":"str","_input_type":"MessageInput"},"max_output_tokens":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"max_output_tokens","value":"","display_name":"Max Output Tokens","advanced":false,"dynamic":false,"info":"The maximum number of tokens to generate.","title_case":false,"type":"int","_input_type":"IntInput"},"model":{"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"model","value":"gemini-2.0-flash-lite","display_name":"Model","advanced":false,"dynamic":false,"info":"The name of the model to use.","title_case":false,"type":"str","_input_type":"StrInput"},"n":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"n","value":"","display_name":"N","advanced":true,"dynamic":false,"info":"Number of chat completions to generate for each prompt. Note that the API may not return the full n completions if duplicates are generated.","title_case":false,"type":"int","_input_type":"IntInput"},"stream":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"stream","value":false,"display_name":"Stream","advanced":false,"dynamic":false,"info":"Stream the response from the model. Streaming works only in Chat.","title_case":false,"type":"bool","_input_type":"BoolInput"},"system_message":{"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"system_message","value":"","display_name":"System Message","advanced":false,"input_types":["Message"],"dynamic":false,"info":"System message to pass to the model.","title_case":false,"type":"str","_input_type":"MessageTextInput"},"temperature":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"temperature","value":0.6,"display_name":"Temperature","advanced":false,"dynamic":false,"info":"","title_case":false,"type":"float","_input_type":"FloatInput","load_from_db":false},"top_k":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"top_k","value":"","display_name":"Top K","advanced":true,"dynamic":false,"info":"Decode using top-k sampling: consider the set of top_k most probable tokens. Must be positive.","title_case":false,"type":"int","_input_type":"IntInput"},"top_p":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"top_p","value":"","display_name":"Top P","advanced":true,"dynamic":false,"info":"The maximum cumulative probability of tokens to consider when sampling.","title_case":false,"type":"float","_input_type":"FloatInput"}},"description":"Generate text using Google Generative AI.","icon":"GoogleGenerativeAI","base_classes":["LanguageModel","Message"],"display_name":"Google Generative AI","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"text_output","display_name":"Text","method":"text_response","value":"__UNDEFINED__","cache":true,"required_inputs":[]},{"types":["LanguageModel"],"selected":"LanguageModel","name":"model_output","display_name":"Language Model","method":"build_model","value":"__UNDEFINED__","cache":true,"required_inputs":[]}],"field_order":["input_value","system_message","stream","max_output_tokens","model","google_api_key","top_p","temperature","n","top_k","output_parser"],"beta":false,"legacy":false,"edited":true,"metadata":{},"tool_mode":false,"lf_version":"1.1.0"},"type":"GoogleGenerativeAIModel","id":"GoogleGenerativeAIModel-WF3Qa"},"selected":false,"width":320,"height":752,"positionAbsolute":{"x":1368.9854733326504,"y":75.78075365427628},"dragging":false},{"id":"TextOutput-JG4jm","type":"genericNode","position":{"x":1833.45143973218,"y":360.50353471429383},"data":{"node":{"template":{"_type":"Component","code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.base.io.text import TextComponent\nfrom langflow.io import MultilineInput, Output\nfrom langflow.schema.message import Message\n\n\nclass TextOutputComponent(TextComponent):\n    display_name = \"Text Output\"\n    description = \"Display a text output in the Playground.\"\n    icon = \"type\"\n    name = \"TextOutput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Text to be passed as output.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"text_response\"),\n    ]\n\n    def text_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n        )\n        self.status = self.input_value\n        return message\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"input_value":{"tool_mode":false,"trace_as_input":true,"multiline":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"input_value","value":"","display_name":"Text","advanced":false,"input_types":["Message"],"dynamic":false,"info":"Text to be passed as output.","title_case":false,"type":"str","_input_type":"MultilineInput"}},"description":"Display a text output in the Playground.","icon":"type","base_classes":["Message"],"display_name":"Text Output","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"text","display_name":"Text","method":"text_response","value":"__UNDEFINED__","cache":true}],"field_order":["input_value"],"beta":false,"legacy":false,"edited":false,"metadata":{},"tool_mode":false,"lf_version":"1.1.0"},"type":"TextOutput","id":"TextOutput-JG4jm"},"selected":true,"width":320,"height":231,"positionAbsolute":{"x":1833.45143973218,"y":360.50353471429383},"dragging":false}],"edges":[{"source":"ParseJSONData-fLPKf","sourceHandle":"{œdataTypeœ:œParseJSONDataœ,œidœ:œParseJSONData-fLPKfœ,œnameœ:œfiltered_dataœ,œoutput_typesœ:[œDataœ]}","target":"ParseData-htcyL","targetHandle":"{œfieldNameœ:œdataœ,œidœ:œParseData-htcyLœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}","data":{"targetHandle":{"fieldName":"data","id":"ParseData-htcyL","inputTypes":["Data"],"type":"other"},"sourceHandle":{"dataType":"ParseJSONData","id":"ParseJSONData-fLPKf","name":"filtered_data","output_types":["Data"]}},"id":"reactflow__edge-ParseJSONData-fLPKf{œdataTypeœ:œParseJSONDataœ,œidœ:œParseJSONData-fLPKfœ,œnameœ:œfiltered_dataœ,œoutput_typesœ:[œDataœ]}-ParseData-htcyL{œfieldNameœ:œdataœ,œidœ:œParseData-htcyLœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}","animated":false,"className":""},{"source":"ParseData-htcyL","sourceHandle":"{œdataTypeœ:œParseDataœ,œidœ:œParseData-htcyLœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}","target":"GoogleGenerativeAIModel-WF3Qa","targetHandle":"{œfieldNameœ:œinput_valueœ,œidœ:œGoogleGenerativeAIModel-WF3Qaœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"input_value","id":"GoogleGenerativeAIModel-WF3Qa","inputTypes":["Message"],"type":"str"},"sourceHandle":{"dataType":"ParseData","id":"ParseData-htcyL","name":"text","output_types":["Message"]}},"id":"reactflow__edge-ParseData-htcyL{œdataTypeœ:œParseDataœ,œidœ:œParseData-htcyLœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-GoogleGenerativeAIModel-WF3Qa{œfieldNameœ:œinput_valueœ,œidœ:œGoogleGenerativeAIModel-WF3Qaœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","animated":false,"className":""},{"source":"GoogleGenerativeAIModel-WF3Qa","sourceHandle":"{œdataTypeœ:œGoogleGenerativeAIModelœ,œidœ:œGoogleGenerativeAIModel-WF3Qaœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}","target":"TextOutput-JG4jm","targetHandle":"{œfieldNameœ:œinput_valueœ,œidœ:œTextOutput-JG4jmœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"input_value","id":"TextOutput-JG4jm","inputTypes":["Message"],"type":"str"},"sourceHandle":{"dataType":"GoogleGenerativeAIModel","id":"GoogleGenerativeAIModel-WF3Qa","name":"text_output","output_types":["Message"]}},"id":"reactflow__edge-GoogleGenerativeAIModel-WF3Qa{œdataTypeœ:œGoogleGenerativeAIModelœ,œidœ:œGoogleGenerativeAIModel-WF3Qaœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-TextOutput-JG4jm{œfieldNameœ:œinput_valueœ,œidœ:œTextOutput-JG4jmœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","animated":false,"className":""},{"source":"TextInput-O9glu","sourceHandle":"{œdataTypeœ:œTextInputœ,œidœ:œTextInput-O9gluœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}","target":"ParseJSONData-fLPKf","targetHandle":"{œfieldNameœ:œinput_valueœ,œidœ:œParseJSONData-fLPKfœ,œinputTypesœ:[œMessageœ,œDataœ],œtypeœ:œotherœ}","data":{"targetHandle":{"fieldName":"input_value","id":"ParseJSONData-fLPKf","inputTypes":["Message","Data"],"type":"other"},"sourceHandle":{"dataType":"TextInput","id":"TextInput-O9glu","name":"text","output_types":["Message"]}},"id":"reactflow__edge-TextInput-O9glu{œdataTypeœ:œTextInputœ,œidœ:œTextInput-O9gluœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-ParseJSONData-fLPKf{œfieldNameœ:œinput_valueœ,œidœ:œParseJSONData-fLPKfœ,œinputTypesœ:[œMessageœ,œDataœ],œtypeœ:œotherœ}","animated":false,"className":""}],"viewport":{"x":-1472.1656735166666,"y":-205.1222616122543,"zoom":1.1072530757974086}},"description":"Empowering Enterprises with Intelligent Interactions.","name":"SparkLLM","last_tested_version":"1.1.0","endpoint_name":null,"is_component":false}